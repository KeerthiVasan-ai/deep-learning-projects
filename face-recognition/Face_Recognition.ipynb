{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Augumentation"
      ],
      "metadata": {
        "id": "Fw53vuqMPgAE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SmyopxVs3XK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "\n",
        "def generate_augmented_images(input_image_path, output_folder_path, num_augmentations=10):\n",
        "    if not os.path.exists(output_folder_path):\n",
        "        os.makedirs(output_folder_path)\n",
        "    else:\n",
        "        if len(os.listdir(output_folder_path)) > 0:\n",
        "            pass\n",
        "\n",
        "    image = tf.keras.preprocessing.image.load_img(input_image_path, target_size=(224, 224))\n",
        "    image_array = tf.keras.preprocessing.image.img_to_array(image)\n",
        "    image_array = image_array / 255.0\n",
        "\n",
        "    datagen = ImageDataGenerator(\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    )\n",
        "\n",
        "\n",
        "    augmented_images = datagen.flow(image_array[None, :, :, :], batch_size=1)\n",
        "\n",
        "    for i, batch in enumerate(augmented_images):\n",
        "        augmented_image = batch[0]\n",
        "        output_image_path = os.path.join(output_folder_path, f\"{i+1}.jpg\")\n",
        "        tf.keras.preprocessing.image.array_to_img(augmented_image * 255.0).save(output_image_path)\n",
        "\n",
        "        if i == num_augmentations - 1:\n",
        "            break\n",
        "\n",
        "    print(f\"Generated {num_augmentations} augmented images and saved them to '{output_folder_path}'\")\n",
        "\n",
        "input_image_path = \"/content/drive/MyDrive/AI_and_ML_Face_Dataset/Keerthi/keerthi.jpg\"\n",
        "output_folder_path = \"/content/drive/MyDrive/AI_and_ML_Face_Dataset/Keerthi\"\n",
        "generate_augmented_images(input_image_path, output_folder_path, num_augmentations=15)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Face Recognition"
      ],
      "metadata": {
        "id": "WyfdU5fpQ4V0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Generating Training and Testing Data"
      ],
      "metadata": {
        "id": "4XHmaOcYPs_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TrainingImagePath='/content/drive/MyDrive/AI_and_ML_Face_Dataset'\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        shear_range=0.1,\n",
        "        zoom_range=0.1,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator()\n",
        "\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "        TrainingImagePath,\n",
        "        target_size=(64, 64),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "        TrainingImagePath,\n",
        "        target_size=(64, 64),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "test_set.class_indices"
      ],
      "metadata": {
        "id": "YnC1pCZzuDPi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f39b923b-c9c3-4188-b18f-90db1d870468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 96 images belonging to 6 classes.\n",
            "Found 96 images belonging to 6 classes.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Ambi': 0, 'Dharma': 1, 'Hari': 2, 'Keerthi': 3, 'Pazham': 4, 'Sanjay': 5}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Deciding Output Neuron"
      ],
      "metadata": {
        "id": "7r0ZZuizP6m7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TrainClasses=training_set.class_indices\n",
        "\n",
        "ResultMap={}\n",
        "for faceValue,faceName in zip(TrainClasses.values(),TrainClasses.keys()):\n",
        "    ResultMap[faceValue]=faceName\n",
        "\n",
        "import pickle\n",
        "with open(\"ResultsMap.pkl\", 'wb') as fileWriteStream:\n",
        "    pickle.dump(ResultMap, fileWriteStream)\n",
        "\n",
        "print(\"Mapping of Face and its ID\",ResultMap)\n",
        "\n",
        "OutputNeurons=len(ResultMap)\n",
        "print('\\n The Number of output neurons: ', OutputNeurons)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8mabje86h-M",
        "outputId": "6aa4ceac-c27e-4c48-ed38-3a24259df30c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mapping of Face and its ID {0: 'Ambi', 1: 'Dharma', 2: 'Hari', 3: 'Keerthi', 4: 'Pazham', 5: 'Sanjay'}\n",
            "\n",
            " The Number of output neurons:  6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model Creation"
      ],
      "metadata": {
        "id": "NvGpNYd0Qf3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPool2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "\n",
        "classifier= Sequential()\n",
        "\n",
        "classifier.add(Convolution2D(32, kernel_size=(5, 5), strides=(1, 1), input_shape=(64,64,3), activation='relu'))\n",
        "classifier.add(MaxPool2D(pool_size=(2,2)))\n",
        "classifier.add(Convolution2D(64, kernel_size=(5, 5), strides=(1, 1), activation='relu'))\n",
        "classifier.add(MaxPool2D(pool_size=(2,2)))\n",
        "classifier.add(Flatten())\n",
        "classifier.add(Dense(64, activation='relu'))\n",
        "classifier.add(Dense(OutputNeurons, activation='softmax'))\n",
        "\n",
        "classifier.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics=[\"accuracy\"])\n",
        "\n",
        "classifier.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIZOj2ys6u9K",
        "outputId": "d120c764-f345-4ec3-c9cf-3d43e0b946d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 60, 60, 32)        2432      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 30, 30, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 26, 26, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 13, 13, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 10816)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                692288    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 6)                 390       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 746,374\n",
            "Trainable params: 746,374\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model Fitting"
      ],
      "metadata": {
        "id": "NSQOWPIvQkmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.fit_generator(\n",
        "                    training_set,\n",
        "                    epochs=15,\n",
        "                    validation_data=test_set,\n",
        "                    validation_steps=10)"
      ],
      "metadata": {
        "id": "NtGuga8rQbMo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7a13b74-88e7-477f-df8a-ee7cccad8884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-f9915a5c690b>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  classifier.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "3/3 [==============================] - ETA: 0s - loss: 186.1616 - accuracy: 0.1458"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 23s 6s/step - loss: 186.1616 - accuracy: 0.1458 - val_loss: 118.0500 - val_accuracy: 0.1667\n",
            "Epoch 2/15\n",
            "3/3 [==============================] - 2s 607ms/step - loss: 53.9615 - accuracy: 0.1562\n",
            "Epoch 3/15\n",
            "3/3 [==============================] - 1s 386ms/step - loss: 2.3033 - accuracy: 0.1979\n",
            "Epoch 4/15\n",
            "3/3 [==============================] - 1s 369ms/step - loss: 1.5466 - accuracy: 0.2500\n",
            "Epoch 5/15\n",
            "3/3 [==============================] - 1s 377ms/step - loss: 1.3835 - accuracy: 0.3438\n",
            "Epoch 6/15\n",
            "3/3 [==============================] - 1s 386ms/step - loss: 1.2855 - accuracy: 0.4271\n",
            "Epoch 7/15\n",
            "3/3 [==============================] - 1s 380ms/step - loss: 1.2372 - accuracy: 0.5104\n",
            "Epoch 8/15\n",
            "3/3 [==============================] - 2s 571ms/step - loss: 1.1500 - accuracy: 0.5312\n",
            "Epoch 9/15\n",
            "3/3 [==============================] - 2s 536ms/step - loss: 0.9552 - accuracy: 0.5833\n",
            "Epoch 10/15\n",
            "3/3 [==============================] - 1s 374ms/step - loss: 0.8404 - accuracy: 0.6458\n",
            "Epoch 11/15\n",
            "3/3 [==============================] - 1s 391ms/step - loss: 0.7477 - accuracy: 0.6562\n",
            "Epoch 12/15\n",
            "3/3 [==============================] - 1s 393ms/step - loss: 0.6869 - accuracy: 0.7396\n",
            "Epoch 13/15\n",
            "3/3 [==============================] - 1s 391ms/step - loss: 0.5372 - accuracy: 0.7812\n",
            "Epoch 14/15\n",
            "3/3 [==============================] - 1s 395ms/step - loss: 0.4469 - accuracy: 0.8333\n",
            "Epoch 15/15\n",
            "3/3 [==============================] - 2s 640ms/step - loss: 0.3640 - accuracy: 0.8750\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7c9a80276da0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prediction"
      ],
      "metadata": {
        "id": "gV7Ozqc_Qqic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.utils import load_img,img_to_array\n",
        "import cv2\n",
        "from keras.preprocessing import image\n",
        "\n",
        "ImagePath='/content/drive/MyDrive/AI_and_ML_Face_Dataset/Keerthi/0.jpg'\n",
        "test_image=load_img(ImagePath,target_size=(64, 64))\n",
        "test_image=img_to_array(test_image)\n",
        "\n",
        "cv2.imshow(test_image)\n",
        "\n",
        "test_image=np.expand_dims(test_image,axis=0)\n",
        "\n",
        "result=classifier.predict(test_image,verbose=0)\n",
        "\n",
        "print('####'*10)\n",
        "print('Prediction is: ',ResultMap[np.argmax(result)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQI41Xq87Vav",
        "outputId": "c52e823e-85f2-4576-e0ee-39cf2082c715"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "DisabledFunctionError",
          "evalue": "cv2.imshow() is disabled in Colab, because it causes Jupyter sessions\nto crash; see https://github.com/jupyter/notebook/issues/3935.\nAs a substitution, consider using\n  from google.colab.patches import cv2_imshow\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mDisabledFunctionError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-c7e45b8b2760>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtest_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtest_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_import_hooks/_cv2.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mDisabledFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDisabledFunctionError\u001b[0m: cv2.imshow() is disabled in Colab, because it causes Jupyter sessions\nto crash; see https://github.com/jupyter/notebook/issues/3935.\nAs a substitution, consider using\n  from google.colab.patches import cv2_imshow\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_snippet",
                "actionText": "Search Snippets for cv2.imshow",
                "snippetFilter": "cv2.imshow"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JwKdQFw580U4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}